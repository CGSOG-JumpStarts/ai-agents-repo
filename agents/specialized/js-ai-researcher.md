# AI Jump Start Researcher - Multi-Agent Research System

## Agents / Agentic Workflows Name

-   **Chief Editor Agent (Orchestrator)**: Manages the entire research and report generation lifecycle, coordinating other specialized agents using LangGraph.
-   **Research Agent**: Conducts initial broad research and in-depth research on specific subtopics using the core `GPTResearcher` library.
-   **Editor Agent**: Plans the report outline (sections/subtopics) based on initial research and manages parallel research execution for these sections.
-   **Reviewer Agent**: Validates the correctness and quality of research drafts against specified guidelines using an LLM.
-   **Reviser Agent**: Revises research drafts based on feedback from the Reviewer Agent using an LLM.
-   **Writer Agent**: Compiles approved research sections into a coherent final report, writing the introduction, conclusion, table of contents, and formatting references using an LLM.
-   **Publisher Agent**: Formats and publishes the final report into various outputs like Markdown, PDF, and DOCX.
-   **Human Agent**: (Optional) Provides feedback on the research plan generated by the Editor Agent.

## Agent / Workflow Description

This system is an advanced multi-agent framework designed for comprehensive, automated research and report generation. It leverages a team of specialized AI agents, orchestrated by a Chief Editor Agent, to manage the complexities of the research lifecycle. The workflow proceeds as follows:

1.  The user provides a research query (task). The **Chief Editor Agent** initiates and oversees the entire process.
2.  The **Research Agent** (utilizing the core `GPTResearcher` library) performs initial web research to gather preliminary information related to the query.
3.  The **Editor Agent** analyzes this initial research and devises a detailed report outline, breaking down the main topic into manageable sections or subtopics.
4.  (Optional) If human-in-the-loop is enabled, the **Human Agent** is presented with the planned outline and can provide feedback. The Editor Agent will revise the plan if feedback is given.
5.  For each section/subtopic in the approved outline, the **Editor Agent** triggers a dedicated sub-workflow:
    *   The **Research Agent** conducts focused, in-depth research on the specific subtopic.
    *   The generated draft for the subtopic is then passed to the **Reviewer Agent**, which assesses its quality, accuracy, and adherence to any predefined guidelines.
    *   If the Reviewer Agent flags issues or requests changes, the draft is sent to the **Reviser Agent**. The Reviser Agent modifies the draft based on the reviewer's feedback.
    *   This review-revise loop can iterate until the Reviewer Agent approves the section draft.
6.  Once all section drafts are researched, reviewed, and approved, they are passed to the **Writer Agent**. The Writer Agent synthesizes these sections, crafts an introduction and conclusion, generates a table of contents, and formats all references, producing a complete research report.
7.  Finally, the **Publisher Agent** takes the final written report (typically in Markdown) and converts/publishes it into various user-specified formats, such as PDF and DOCX.

The entire workflow is built on LangGraph, enabling robust state management, conditional logic, and parallel execution of research tasks for different sections.

## Domain / Industry

-   General Purpose Research
-   Automated Content Generation
-   Information Retrieval and Synthesis
-   Academic Research Assistance
-   Business Intelligence

## Tools / Functions Used By Agents

### Chief Editor Agent (Orchestrator):
-   Manages LangGraph state and transitions.
-   Delegates tasks to specialized agents.
-   Aggregates results from different agents.
-   Uses: LangGraph library.

### Research Agent:
-   `run_initial_research(query, source, tone, headers)`: Performs broad initial research.
-   `run_depth_research(parent_query, subtopic, source, headers)`: Conducts focused research on subtopics.
-   Internally uses `GPTResearcher` library which employs:
    -   LLMs (e.g., OpenAI GPT-4o, configurable) for query planning, summarization, and report generation.
    -   Web Retrievers (e.g., Tavily, Google Search API) for finding online sources.
    -   Web Scrapers (e.g., BeautifulSoup, Selenium/NoDriver, Firecrawl) for extracting content from URLs.
    -   Document Loaders (e.g., PyMuPDFLoader) for local file processing.
    -   Vector Stores (optional, e.g., FAISS, PGVector) for semantic search over ingested content.

### Editor Agent:
-   `plan_research(initial_research_summary, task_details)`: Generates a report outline (title, sections) using an LLM.
-   `run_parallel_research(sections, task_details)`: Manages parallel execution of the (Research -> Review -> Revise) sub-workflow for each section using LangGraph.
-   Uses: LLMs, LangGraph.

### Reviewer Agent:
-   `review_draft(draft, guidelines)`: Assesses a draft against guidelines and provides feedback using an LLM.
-   Uses: LLMs.

### Reviser Agent:
-   `revise_draft(draft, review_notes)`: Rewrites a draft based on reviewer feedback using an LLM.
-   Uses: LLMs.

### Writer Agent:
-   `write_sections(research_data, query_details)`: Synthesizes researched sections, writes introduction, conclusion, table of contents, and references using an LLM.
-   Uses: LLMs.

### Publisher Agent:
-   `publish_research_report(report_content, formats)`: Converts the final Markdown report to other specified formats.
-   `write_md_to_pdf()`: Converts Markdown to PDF.
-   `write_md_to_word()`: Converts Markdown to DOCX.
-   `write_text_to_md()`: Saves text as a Markdown file.
-   Uses: `md2pdf`, `mistune`, `python-docx` libraries.

### Human Agent:
-   `review_plan(layout)`: Presents the report plan to a human user for feedback (via console or WebSocket).
-   Uses: User I/O (console/WebSocket).

### Shared External Services & Libraries:
-   **Large Language Models (LLMs)**: OpenAI API (default), Anthropic, Azure OpenAI, etc. (configurable via `gpt_researcher.llm_provider`).
-   **Search Engine APIs**: Tavily API (default), Google Search, Bing Search, etc. (configurable via `gpt_researcher.retrievers`).
-   **Web Scraping Libraries**: BeautifulSoup, Selenium, NoDriver, Firecrawl, TavilyExtract (configurable via `gpt_researcher.scraper`).
-   **Document Processing Libraries**: `PyMuPDFLoader`, `UnstructuredWordDocumentLoader`, `md2pdf`, `mistune`, `python-docx`.
-   **LangGraph**: For orchestrating the agentic workflow.
-   **Embedding Models & Vector Stores**: (Optional, used by core `GPTResearcher`) OpenAI Embeddings, FAISS, etc.

## Architecture Design

```mermaid
graph TD
    UserTask[User Task/Query] --> ChiefEditor[ChiefEditorAgent Orchestrator]

    subgraph ResearchPlanningPhase [Research Planning Phase]
        ChiefEditor -->|1. Initial Research Request| ResearchAgent_Initial["ResearchAgent: Initial Research (uses GPTResearcher)"]
        ResearchAgent_Initial -- Initial Findings --> EditorAgent_Plan[EditorAgent: Plan Report Outline]
        EditorAgent_Plan -- Proposed Outline --> HumanAgent_Review{HumanAgent: Review Plan?}
        HumanAgent_Review -- Optional Feedback --> EditorAgent_Plan
        HumanAgent_Review -- "No Feedback / Approve" --> ParallelResearchTrigger["Trigger Parallel Section Research"]
    end

    ParallelResearchTrigger --> EditorAgent_SubWorkflow["EditorAgent: Manage Sub-Workflow (LangGraph) for each Section"]

    subgraph SectionResearchSubWorkflow [Section Research Sub-Workflow (Iterates per Section)]
        direction LR
        EditorAgent_SubWorkflow -->|Sub-topic Query| ResearchAgent_Depth["ResearchAgent: In-Depth Research (uses GPTResearcher)"]
        ResearchAgent_Depth -->|Section Draft| ReviewerAgent[ReviewerAgent: Review Draft]
        ReviewerAgent -- "Needs Revision" --> ReviserAgent[ReviserAgent: Revise Draft]
        ReviserAgent --> ReviewerAgent
        ReviewerAgent -- "Approved" --> ApprovedSectionDraft((Approved Section Draft))
    end
    
    ApprovedSectionDraft --> ChiefEditor_Collects[ChiefEditorAgent: Collects Approved Sections]

    subgraph ReportCompilationPhase [Report Compilation & Publishing Phase]
        ChiefEditor_Collects -->|Aggregated Approved Sections| WriterAgent[WriterAgent: Compile & Write Full Report]
        WriterAgent -->|Final Report Draft (Markdown)| PublisherAgent[PublisherAgent: Format & Publish Report]
        PublisherAgent -->|Published Reports (MD, PDF, DOCX)| UserOutput[User Output Files]
    end

    subgraph ExternalToolsAndServices [External Tools & Services]
        LLMApis["LLM APIs (e.g., OpenAI)"]
        SearchEngines["Search Engine APIs (e.g., Tavily)"]
        WebScrapers["Web Scraping Libraries"]
        DocProcessingLibs["Document Processing Libs (md2pdf, python-docx)"]
        LangGraphLib["LangGraph Library for Orchestration"]
    end

    ResearchAgent_Initial --> LLMApis
    ResearchAgent_Initial --> SearchEngines
    ResearchAgent_Initial --> WebScrapers
    
    EditorAgent_Plan --> LLMApis
    
    ResearchAgent_Depth --> LLMApis
    ResearchAgent_Depth --> SearchEngines
    ResearchAgent_Depth --> WebScrapers

    ReviewerAgent --> LLMApis
    ReviserAgent --> LLMApis
    WriterAgent --> LLMApis
    PublisherAgent --> DocProcessingLibs

    ChiefEditor --> LangGraphLib
    EditorAgent_SubWorkflow --> LangGraphLib
```

The architecture depicts a sophisticated multi-agent system where the **ChiefEditorAgent** orchestrates a series of specialized agents to perform comprehensive research. The process begins with initial research by the **ResearchAgent**, followed by plan generation by the **EditorAgent**, which can optionally be reviewed by a **HumanAgent**. Approved plans lead to parallel in-depth research on subtopics, each managed by a cycle of research, review (**ReviewerAgent**), and revision (**ReviserAgent**). Finally, the **WriterAgent** compiles the complete report, and the **PublisherAgent** handles output formatting. The system relies heavily on LLMs, Search APIs, Web Scraping tools, and LangGraph for its operations. The core `GPTResearcher` library provides the foundational research capabilities used by the `ResearchAgent`.